{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13aaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c23117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.options.display.float_format = '{:,.6f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c77d30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_FOLDER=\"anotações_humanas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca165d9",
   "metadata": {},
   "source": [
    "### Mapping 4-score to 3-score evaluations to match GPT-4 3-score evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4c9823",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mapper = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    2:1,\n",
    "    3:2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4f127",
   "metadata": {},
   "source": [
    "### Original 4-score to 3-score evaluations mapping\n",
    "\n",
    "This mapping changes the original 4-score 1 evaluation meaning, indicating it **partially answers to the question**, while the original (TREC-DL 21) meaning is the passage **does not answer to the question**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb766ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mapper_original = {\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:1,\n",
    "    3:2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade176f7",
   "metadata": {},
   "source": [
    "### Mapping 4-score to 2-score evenly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cc56c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mapper_for_2 = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    2:1,\n",
    "    3:1    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f801f68",
   "metadata": {},
   "source": [
    "### Alternative version for mapping 4-score to 2-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e27068",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mapper_for_2_alt = {\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:1,\n",
    "    3:1    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86e2ce",
   "metadata": {},
   "source": [
    "### Mapping 3-score to 2-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ca27fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mapper_3_for_2 = {\n",
    "    0:0,\n",
    "    1:1,\n",
    "    2:1    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c312ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_agreement_per_questions(evaluation_a, evaluation_b, suffix=None, score='score'):\n",
    "    \n",
    "    merged_df = evaluation_a.merge(evaluation_b, left_on='doccano_id', right_on='doccano_id')[['query_x', 'passage_x', 'passage_id_x', score + '_x', score + '_y']]\n",
    "    \n",
    "    correlations = []\n",
    "    \n",
    "    for group_name, group_df in merged_df.groupby('query_x', sort=False):\n",
    "        correlations.append({'query': group_name,\n",
    "                             'cohen_kappa{}'.format(suffix): cohen_kappa_score(group_df[score + '_x'], group_df[score + '_y'])})\n",
    "        \n",
    "    return merged_df, pd.DataFrame(correlations).fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b6c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_data_consolidated(correlation_df, columns_to_plot, plot_title):\n",
    "    \n",
    "    fig = plt.figure(figsize=[10, 10])\n",
    "\n",
    "    fig.suptitle(plot_title, y=0.91)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    all_boxplots = plt.boxplot(correlation_df[columns_to_plot], patch_artist=True, vert=False, meanline=True, showmeans=True)\n",
    "\n",
    "    colors = ['pink', 'lightblue', 'lightgreen']\n",
    "    \n",
    "    all_boxes = all_boxplots['boxes']\n",
    "    \n",
    "    print(all_boxes)\n",
    "    \n",
    "    for i, which_box in enumerate(all_boxes):\n",
    "        which_box.set_facecolor(colors[i // 3])\n",
    "    \n",
    "    \n",
    "    plt.yticks(range(1, len(columns_to_plot) + 1), columns_to_plot)\n",
    "    plt.xticks(np.arange(-0.3, 1.0, 0.1))\n",
    "    \n",
    "    plt.legend(handles=all_boxes[::3], labels=[\"Humanos x Humanos\", \"Humanos x GPT3.5\", \"Humanos x GPT4\"], bbox_to_anchor=(1.0, 1.0))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f154b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_data(correlation_df, columns_to_plot, plot_title):\n",
    "    \n",
    "    fig = plt.figure(figsize=[15, 40])\n",
    "\n",
    "    fig.suptitle(plot_title, y=0.91)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    all_boxplots = plt.boxplot(correlation_df[columns_to_plot].to_numpy().transpose(), patch_artist=True, vert=False, meanline=True, showmeans=True)\n",
    "\n",
    "    colors = ['pink', 'lightblue', 'lightgreen', 'lightyellow'][::-1]\n",
    "    \n",
    "    all_boxes = all_boxplots['boxes']\n",
    "    \n",
    "#     print(all_boxes)\n",
    "    \n",
    "    for i, which_box in enumerate(all_boxes):\n",
    "        which_box.set_facecolor(colors[i % 4])\n",
    "\n",
    "        \n",
    "    \n",
    "    plt.yticks(range(4, correlation_df.shape[0] + 1, 4), correlation_df.iloc[::4]['query'])\n",
    "    plt.xticks(np.arange(-0.3, 1.0, 0.1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4266482",
   "metadata": {},
   "source": [
    "## Read human annotators evaluations and map the original 4-score values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28e99c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"admin_240_annotations_with_questions.tsv\"), sep='\\t')\n",
    "a2_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"Eduardo_240_annotations_with_questions.tsv\"), sep='\\t')\n",
    "a3_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"Leodecio_240_annotations_with_questions.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9092e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_df['03_score'] = a1_df['score'].map(score_mapper)\n",
    "a2_df['03_score'] = a2_df['score'].map(score_mapper)\n",
    "a3_df['03_score'] = a3_df['score'].map(score_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3112f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_df['02_score'] = a1_df['score'].map(score_mapper_for_2)\n",
    "a2_df['02_score'] = a2_df['score'].map(score_mapper_for_2)\n",
    "a3_df['02_score'] = a3_df['score'].map(score_mapper_for_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194fea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_df['02_score_alt'] = a1_df['score'].map(score_mapper_for_2_alt)\n",
    "a2_df['02_score_alt'] = a2_df['score'].map(score_mapper_for_2_alt)\n",
    "a3_df['02_score_alt'] = a3_df['score'].map(score_mapper_for_2_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e31bc0",
   "metadata": {},
   "source": [
    "## Read GPT passage evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c393dc",
   "metadata": {},
   "source": [
    "### GPT-4 4-score evaluation, using TREC-DL 21 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36a68e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_240_samples_2nd_round_with_questions.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1cd227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_df['03_score'] = gpt4_df['score'].map(score_mapper)\n",
    "\n",
    "gpt4_df['03_score_2'] = gpt4_df['score'].map(score_mapper_original)\n",
    "\n",
    "gpt4_df['02_score'] = gpt4_df['score'].map(score_mapper_for_2)\n",
    "\n",
    "gpt4_df['02_score_alt'] = gpt4_df['score'].map(score_mapper_for_2_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542c0da5",
   "metadata": {},
   "source": [
    "### GPT-4 4-score evaluation using Chain of Thoughts (CoT) prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d868780",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_1st_cot_2_6_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_120_samples_1st_queries_set_prompt_v2.6.tsv\"), sep='\\t')\n",
    "gpt4_2nd_cot_2_6_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_120_samples_2nd_queries_set_prompt_v2.6.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f32c3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_1st_cot_2_6_df['02_score'] = gpt4_1st_cot_2_6_df['score'].map(score_mapper_for_2)\n",
    "gpt4_2nd_cot_2_6_df['02_score'] = gpt4_2nd_cot_2_6_df['score'].map(score_mapper_for_2)\n",
    "\n",
    "gpt4_1st_cot_2_6_df['02_score_alt'] = gpt4_1st_cot_2_6_df['score'].map(score_mapper_for_2_alt)\n",
    "gpt4_2nd_cot_2_6_df['02_score_alt'] = gpt4_2nd_cot_2_6_df['score'].map(score_mapper_for_2_alt)\n",
    "\n",
    "gpt4_1st_cot_2_6_df['03_score'] = gpt4_1st_cot_2_6_df['score'].map(score_mapper)\n",
    "gpt4_2nd_cot_2_6_df['03_score'] = gpt4_2nd_cot_2_6_df['score'].map(score_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f8779c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt4_cot_2_6_df = pd.concat([gpt4_1st_cot_2_6_df, gpt4_2nd_cot_2_6_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ce738cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_cot_2_6_df.to_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_240_samples_prompt_v2.6.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f745e",
   "metadata": {},
   "source": [
    "### GPT-4 3-score evaluation with prompt based on orignal 4-score evaluation prompt\n",
    "\n",
    "Just removing the score 1 decription from the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515022d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_1st_03_score_2_7_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_120_samples_1st_queries_set_prompt_v2.7.tsv\"), sep='\\t')\n",
    "gpt4_2nd_03_score_2_7_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_120_samples_2nd_queries_set_prompt_v2.7.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e679f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_1st_03_score_2_7_df['02_score'] = gpt4_1st_03_score_2_7_df['score'].map(score_mapper_3_for_2)\n",
    "gpt4_2nd_03_score_2_7_df['02_score'] = gpt4_2nd_03_score_2_7_df['score'].map(score_mapper_3_for_2)\n",
    "\n",
    "gpt4_1st_03_score_2_7_df['02_score_alt'] = gpt4_1st_03_score_2_7_df['score'].map(score_mapper_3_for_2)\n",
    "gpt4_2nd_03_score_2_7_df['02_score_alt'] = gpt4_2nd_03_score_2_7_df['score'].map(score_mapper_3_for_2)\n",
    "\n",
    "gpt4_1st_03_score_2_7_df['03_score'] = gpt4_1st_03_score_2_7_df['score']\n",
    "gpt4_2nd_03_score_2_7_df['03_score'] = gpt4_2nd_03_score_2_7_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b333edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_03_score_2_7_df = pd.concat([gpt4_1st_03_score_2_7_df, gpt4_2nd_03_score_2_7_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79634269",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_03_score_2_7_df.to_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_240_samples_prompt_v2.7.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4e235",
   "metadata": {},
   "source": [
    "### GPT-4 3-score evaluation with prompt with 3 scores translated from MS paper\n",
    "\n",
    "3 scores translation from \"Large Language models can accurately predict searcher preferences\", from Thomas et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ac58159",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_2nd_03_score_2_8_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_120_samples_2nd_queries_set_prompt_v2.8.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03e2459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_2nd_03_score_2_8_df['02_score'] = gpt4_2nd_03_score_2_8_df['score'].map(score_mapper_3_for_2)\n",
    "gpt4_2nd_03_score_2_8_df['02_score_alt'] = gpt4_2nd_03_score_2_8_df['score'].map(score_mapper_3_for_2)\n",
    "gpt4_2nd_03_score_2_8_df['03_score'] = gpt4_2nd_03_score_2_8_df['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aaad19",
   "metadata": {},
   "source": [
    "### GPT-4 3-score evaluation using simplified original 4-score prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6faf47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_1st_03_score_2_9_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_120_samples_1st_queries_set_prompt_v2.9.tsv\"), sep='\\t')\n",
    "gpt4_2nd_03_score_2_9_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_120_samples_2nd_queries_set_prompt_v2.9.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df8b128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_1st_03_score_2_9_df['02_score'] = gpt4_1st_03_score_2_9_df['score'].map(score_mapper_3_for_2)\n",
    "gpt4_2nd_03_score_2_9_df['02_score'] = gpt4_2nd_03_score_2_9_df['score'].map(score_mapper_3_for_2)\n",
    "\n",
    "gpt4_1st_03_score_2_9_df['02_score_alt'] = gpt4_1st_03_score_2_9_df['score'].map(score_mapper_3_for_2)\n",
    "gpt4_2nd_03_score_2_9_df['02_score_alt'] = gpt4_2nd_03_score_2_9_df['score'].map(score_mapper_3_for_2)\n",
    "\n",
    "gpt4_2nd_03_score_2_9_df['03_score'] = gpt4_2nd_03_score_2_9_df['score']\n",
    "gpt4_1st_03_score_2_9_df['03_score'] = gpt4_1st_03_score_2_9_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69db3625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpt4_03_score_2_9_df = pd.concat([gpt4_1st_03_score_2_9_df, gpt4_2nd_03_score_2_9_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b175cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_03_score_2_9_df.to_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_240_samples_prompt_v2.9.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f128e",
   "metadata": {},
   "source": [
    "### GPT-4 4-score evaluation using Chain of Thoughts (CoT) prompt adding completeness and adequacy criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edb0dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_1st_cot_3_0_df = pd.read_csv(os.path.join(ANNOTATIONS_FOLDER, \"gpt_4_evaluations_120_samples_1st_queries_set_prompt_v3.0.tsv\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "618bcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_1st_cot_3_0_df['02_score'] = gpt4_1st_cot_3_0_df['score'].map(score_mapper_for_2)\n",
    "gpt4_1st_cot_3_0_df['02_score_alt'] = gpt4_1st_cot_3_0_df['score'].map(score_mapper_for_2_alt)\n",
    "gpt4_1st_cot_3_0_df['03_score'] = gpt4_1st_cot_3_0_df['score'].map(score_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ffd4d",
   "metadata": {},
   "source": [
    "### Just check that the passages order is exactly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d6024c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(gpt4_cot_2_6_df['doccano_id'] == a3_df['doccano_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f5fd80",
   "metadata": {},
   "source": [
    "## Functions to check the correlation according to the selected score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4016b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations_240_passages(which_score, only_4_scores=False):\n",
    "\n",
    "    general_agreement_df = pd.DataFrame()\n",
    "\n",
    "    general_agreement_df['comparisson'] = ['a1', 'a2', 'a3']\n",
    "\n",
    "    general_agreement_df['a1'] = [np.nan, \n",
    "                                  cohen_kappa_score(a1_df[which_score], a2_df[which_score]), \n",
    "                                  cohen_kappa_score(a1_df[which_score], a3_df[which_score])]\n",
    "\n",
    "    general_agreement_df['a2'] = [cohen_kappa_score(a1_df[which_score], a2_df[which_score]), \n",
    "                                  np.nan, \n",
    "                                  cohen_kappa_score(a2_df[which_score], a3_df[which_score])]\n",
    "\n",
    "    general_agreement_df['a3'] = [cohen_kappa_score(a1_df[which_score], a3_df[which_score]), \n",
    "                                  cohen_kappa_score(a2_df[which_score], a3_df[which_score]), \n",
    "                                  np.nan]\n",
    "\n",
    "    general_agreement_df['GPT4 4-score'] = [cohen_kappa_score(a1_df[which_score], gpt4_df[which_score]), \n",
    "                                            cohen_kappa_score(a2_df[which_score], gpt4_df[which_score]), \n",
    "                                            cohen_kappa_score(a3_df[which_score], gpt4_df[which_score])]\n",
    "\n",
    "    general_agreement_df['GPT4 4-score cot 2.6'] = [cohen_kappa_score(a1_df[which_score], gpt4_cot_2_6_df[which_score]), \n",
    "                                                    cohen_kappa_score(a2_df[which_score], gpt4_cot_2_6_df[which_score]), \n",
    "                                                    cohen_kappa_score(a3_df[which_score], gpt4_cot_2_6_df[which_score])]  \n",
    "    \n",
    "    if not only_4_scores:\n",
    "        general_agreement_df['GPT4 3-score 2.7'] = [cohen_kappa_score(a1_df[which_score], gpt4_03_score_2_7_df[which_score]), \n",
    "                                                    cohen_kappa_score(a2_df[which_score], gpt4_03_score_2_7_df[which_score]), \n",
    "                                                    cohen_kappa_score(a3_df[which_score], gpt4_03_score_2_7_df[which_score])]\n",
    "\n",
    "        general_agreement_df['GPT4 3-score 2.9'] = [cohen_kappa_score(a1_df[which_score], gpt4_03_score_2_9_df[which_score]), \n",
    "                                                    cohen_kappa_score(a2_df[which_score], gpt4_03_score_2_9_df[which_score]), \n",
    "                                                    cohen_kappa_score(a3_df[which_score], gpt4_03_score_2_9_df[which_score])]\n",
    "\n",
    "    \n",
    "    general_agreement_df = pd.concat([general_agreement_df, \n",
    "                                      pd.DataFrame(data=[['mean'] + general_agreement_df.iloc[:, 1:].mean().to_list()], columns=general_agreement_df.columns)])\n",
    "    \n",
    "    human_mean = general_agreement_df.iloc[-1,1:4].mean()\n",
    "    \n",
    "    general_agreement_df = pd.concat([general_agreement_df,\n",
    "                                      pd.DataFrame(data=[['Difference from mean human annotators'] + (general_agreement_df.iloc[-1, 1:] - human_mean).to_list()], columns=general_agreement_df.columns)])\n",
    "    \n",
    "    \n",
    "    return general_agreement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "748665c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations_1st_120_passages(which_score, only_4_scores=False):\n",
    "    \n",
    "    general_agreement_df = pd.DataFrame()\n",
    "\n",
    "    general_agreement_df['comparisson'] = ['a1', 'a2', 'a3']\n",
    "\n",
    "    general_agreement_df['a1'] = [np.nan, \n",
    "                                  cohen_kappa_score(a1_df.iloc[0:120][which_score], a2_df.iloc[0:120][which_score]), \n",
    "                                  cohen_kappa_score(a1_df.iloc[0:120][which_score], a3_df.iloc[0:120][which_score])]\n",
    "\n",
    "    general_agreement_df['a2'] = [cohen_kappa_score(a1_df.iloc[0:120][which_score], a2_df.iloc[0:120][which_score]), \n",
    "                                  np.nan, \n",
    "                                  cohen_kappa_score(a2_df.iloc[0:120][which_score], a3_df.iloc[0:120][which_score])]\n",
    "\n",
    "    general_agreement_df['a3'] = [cohen_kappa_score(a1_df.iloc[0:120][which_score], a3_df.iloc[0:120][which_score]), \n",
    "                                  cohen_kappa_score(a2_df.iloc[0:120][which_score], a3_df.iloc[0:120][which_score]), \n",
    "                                  np.nan]\n",
    "\n",
    "    general_agreement_df['GPT4 1st 4-score'] = [cohen_kappa_score(a1_df.iloc[0:120][which_score], gpt4_df.iloc[0:120][which_score]), \n",
    "                                                cohen_kappa_score(a2_df.iloc[0:120][which_score], gpt4_df.iloc[0:120][which_score]), \n",
    "                                                cohen_kappa_score(a3_df.iloc[0:120][which_score], gpt4_df.iloc[0:120][which_score])]\n",
    "\n",
    "    if not only_4_scores:\n",
    "        general_agreement_df['GPT4 1st 3-score 2.7'] = [cohen_kappa_score(a1_df.iloc[0:120][which_score], gpt4_1st_03_score_2_7_df[which_score]), \n",
    "                                                        cohen_kappa_score(a2_df.iloc[0:120][which_score], gpt4_1st_03_score_2_7_df[which_score]), \n",
    "                                                        cohen_kappa_score(a3_df.iloc[0:120][which_score], gpt4_1st_03_score_2_7_df[which_score])]\n",
    "\n",
    "        general_agreement_df['GPT4 1st 3-score 2.9'] = [cohen_kappa_score(a1_df.iloc[0:120][which_score], gpt4_1st_03_score_2_9_df[which_score]), \n",
    "                                                        cohen_kappa_score(a2_df.iloc[0:120][which_score], gpt4_1st_03_score_2_9_df[which_score]), \n",
    "                                                        cohen_kappa_score(a3_df.iloc[0:120][which_score], gpt4_1st_03_score_2_9_df[which_score])]\n",
    "\n",
    "\n",
    "    general_agreement_df['GPT4 1st 4-score cot 2.6'] = [cohen_kappa_score(a1_df.iloc[0:120][which_score], gpt4_1st_cot_2_6_df[which_score]), \n",
    "                                                        cohen_kappa_score(a2_df.iloc[0:120][which_score], gpt4_1st_cot_2_6_df[which_score]), \n",
    "                                                        cohen_kappa_score(a3_df.iloc[0:120][which_score], gpt4_1st_cot_2_6_df[which_score])]\n",
    "\n",
    "    general_agreement_df['GPT4 1st 4-score cot 3.0'] = [cohen_kappa_score(a1_df.iloc[0:120][which_score], gpt4_1st_cot_3_0_df[which_score]), \n",
    "                                                        cohen_kappa_score(a2_df.iloc[0:120][which_score], gpt4_1st_cot_3_0_df[which_score]), \n",
    "                                                        cohen_kappa_score(a3_df.iloc[0:120][which_score], gpt4_1st_cot_3_0_df[which_score])]  \n",
    "\n",
    "    general_agreement_df = pd.concat([general_agreement_df, \n",
    "                                      pd.DataFrame(data=[['mean'] + general_agreement_df.iloc[:, 1:].mean().to_list()], columns=general_agreement_df.columns)])\n",
    "    \n",
    "    human_mean = general_agreement_df.iloc[-1,1:4].mean()\n",
    "    \n",
    "    general_agreement_df = pd.concat([general_agreement_df,\n",
    "                                      pd.DataFrame(data=[['Difference from mean human annotators'] + (general_agreement_df.iloc[-1, 1:] - human_mean).to_list()], columns=general_agreement_df.columns)])\n",
    "\n",
    "    return general_agreement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb199dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlations_2nd_120_passages(which_score, only_4_scores=False):\n",
    "\n",
    "    general_agreement_df = pd.DataFrame()\n",
    "\n",
    "    general_agreement_df['comparisson'] = ['a1', 'a2', 'a3']\n",
    "\n",
    "    general_agreement_df['a1'] = [np.nan, \n",
    "                                  cohen_kappa_score(a1_df.iloc[120:240][which_score], a2_df.iloc[120:240][which_score]), \n",
    "                                  cohen_kappa_score(a1_df.iloc[120:240][which_score], a3_df.iloc[120:240][which_score])]\n",
    "\n",
    "    general_agreement_df['a2'] = [cohen_kappa_score(a1_df.iloc[120:240][which_score], a2_df.iloc[120:240][which_score]), \n",
    "                                  np.nan, \n",
    "                                  cohen_kappa_score(a2_df.iloc[120:240][which_score], a3_df.iloc[120:240][which_score])]\n",
    "\n",
    "    general_agreement_df['a3'] = [cohen_kappa_score(a1_df.iloc[120:240][which_score], a3_df.iloc[120:240][which_score]), \n",
    "                                  cohen_kappa_score(a2_df.iloc[120:240][which_score], a3_df.iloc[120:240][which_score]), \n",
    "                                  np.nan]\n",
    "\n",
    "    general_agreement_df['GPT4 2nd 4-score'] = [cohen_kappa_score(a1_df.iloc[120:240][which_score], gpt4_df.iloc[120:240][which_score]), \n",
    "                                                cohen_kappa_score(a2_df.iloc[120:240][which_score], gpt4_df.iloc[120:240][which_score]), \n",
    "                                                cohen_kappa_score(a3_df.iloc[120:240][which_score], gpt4_df.iloc[120:240][which_score])]\n",
    "\n",
    "    if not only_4_scores:\n",
    "        general_agreement_df['GPT4 2nd 3-score 2.7'] = [cohen_kappa_score(a1_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_7_df[which_score]), \n",
    "                                                        cohen_kappa_score(a2_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_7_df[which_score]), \n",
    "                                                        cohen_kappa_score(a3_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_7_df[which_score])]\n",
    "\n",
    "        general_agreement_df['GPT4 2nd 3-score 2.8'] = [cohen_kappa_score(a1_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_8_df[which_score]), \n",
    "                                                        cohen_kappa_score(a2_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_8_df[which_score]), \n",
    "                                                        cohen_kappa_score(a3_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_8_df[which_score])]\n",
    "\n",
    "        general_agreement_df['GPT4 2nd 3-score 2.9'] = [cohen_kappa_score(a1_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_9_df[which_score]), \n",
    "                                                        cohen_kappa_score(a2_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_9_df[which_score]), \n",
    "                                                        cohen_kappa_score(a3_df.iloc[120:240][which_score], gpt4_2nd_03_score_2_9_df[which_score])]\n",
    "\n",
    "\n",
    "    general_agreement_df['GPT4 2nd 4-score cot 2.6'] = [cohen_kappa_score(a1_df.iloc[120:240][which_score], gpt4_2nd_cot_2_6_df[which_score]), \n",
    "                                                        cohen_kappa_score(a2_df.iloc[120:240][which_score], gpt4_2nd_cot_2_6_df[which_score]), \n",
    "                                                        cohen_kappa_score(a3_df.iloc[120:240][which_score], gpt4_2nd_cot_2_6_df[which_score])]\n",
    "\n",
    "\n",
    "    general_agreement_df = pd.concat([general_agreement_df, \n",
    "                                      pd.DataFrame(data=[['mean'] + general_agreement_df.iloc[:, 1:].mean().to_list()], columns=general_agreement_df.columns)])\n",
    "    \n",
    "    \n",
    "    human_mean = general_agreement_df.iloc[-1,1:4].mean()\n",
    "    \n",
    "    general_agreement_df = pd.concat([general_agreement_df,\n",
    "                                      pd.DataFrame(data=[['Difference from mean human annotators'] + (general_agreement_df.iloc[-1, 1:] - human_mean).to_list()], columns=general_agreement_df.columns)])\n",
    "\n",
    "    return general_agreement_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043626c4",
   "metadata": {},
   "source": [
    "## Correlations for the 4-score evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2331f123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 4-score</th>\n",
       "      <th>GPT4 4-score cot 2.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.436881</td>\n",
       "      <td>0.429402</td>\n",
       "      <td>0.318134</td>\n",
       "      <td>0.279329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.436881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.410455</td>\n",
       "      <td>0.274609</td>\n",
       "      <td>0.198145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.429402</td>\n",
       "      <td>0.410455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.355155</td>\n",
       "      <td>0.256689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.433142</td>\n",
       "      <td>0.423668</td>\n",
       "      <td>0.419929</td>\n",
       "      <td>0.315966</td>\n",
       "      <td>0.244721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>-0.001911</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>-0.109613</td>\n",
       "      <td>-0.180858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson       a1        a2        a3  \\\n",
       "0                                     a1      NaN  0.436881  0.429402   \n",
       "1                                     a2 0.436881       NaN  0.410455   \n",
       "2                                     a3 0.429402  0.410455       NaN   \n",
       "0                                   mean 0.433142  0.423668  0.419929   \n",
       "0  Difference from mean human annotators 0.007562 -0.001911 -0.005651   \n",
       "\n",
       "   GPT4 4-score  GPT4 4-score cot 2.6  \n",
       "0      0.318134              0.279329  \n",
       "1      0.274609              0.198145  \n",
       "2      0.355155              0.256689  \n",
       "0      0.315966              0.244721  \n",
       "0     -0.109613             -0.180858  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 1st 4-score</th>\n",
       "      <th>GPT4 1st 4-score cot 2.6</th>\n",
       "      <th>GPT4 1st 4-score cot 3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489892</td>\n",
       "      <td>0.575498</td>\n",
       "      <td>0.396985</td>\n",
       "      <td>0.376026</td>\n",
       "      <td>0.388201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.489892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500324</td>\n",
       "      <td>0.419496</td>\n",
       "      <td>0.222163</td>\n",
       "      <td>0.244028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.575498</td>\n",
       "      <td>0.500324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.449490</td>\n",
       "      <td>0.350928</td>\n",
       "      <td>0.301080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.532695</td>\n",
       "      <td>0.495108</td>\n",
       "      <td>0.537911</td>\n",
       "      <td>0.421990</td>\n",
       "      <td>0.316372</td>\n",
       "      <td>0.311103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>-0.026797</td>\n",
       "      <td>0.016006</td>\n",
       "      <td>-0.099914</td>\n",
       "      <td>-0.205532</td>\n",
       "      <td>-0.210802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson       a1        a2       a3  \\\n",
       "0                                     a1      NaN  0.489892 0.575498   \n",
       "1                                     a2 0.489892       NaN 0.500324   \n",
       "2                                     a3 0.575498  0.500324      NaN   \n",
       "0                                   mean 0.532695  0.495108 0.537911   \n",
       "0  Difference from mean human annotators 0.010790 -0.026797 0.016006   \n",
       "\n",
       "   GPT4 1st 4-score  GPT4 1st 4-score cot 2.6  GPT4 1st 4-score cot 3.0  \n",
       "0          0.396985                  0.376026                  0.388201  \n",
       "1          0.419496                  0.222163                  0.244028  \n",
       "2          0.449490                  0.350928                  0.301080  \n",
       "0          0.421990                  0.316372                  0.311103  \n",
       "0         -0.099914                 -0.205532                 -0.210802  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 2nd 4-score</th>\n",
       "      <th>GPT4 2nd 4-score cot 2.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369369</td>\n",
       "      <td>0.286629</td>\n",
       "      <td>0.245213</td>\n",
       "      <td>0.190077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.369369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322651</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.184723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.286629</td>\n",
       "      <td>0.322651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260090</td>\n",
       "      <td>0.161074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.327999</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.304640</td>\n",
       "      <td>0.213709</td>\n",
       "      <td>0.178624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.019794</td>\n",
       "      <td>-0.021576</td>\n",
       "      <td>-0.112507</td>\n",
       "      <td>-0.147592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson       a1       a2        a3  \\\n",
       "0                                     a1      NaN 0.369369  0.286629   \n",
       "1                                     a2 0.369369      NaN  0.322651   \n",
       "2                                     a3 0.286629 0.322651       NaN   \n",
       "0                                   mean 0.327999 0.346010  0.304640   \n",
       "0  Difference from mean human annotators 0.001783 0.019794 -0.021576   \n",
       "\n",
       "   GPT4 2nd 4-score  GPT4 2nd 4-score cot 2.6  \n",
       "0          0.245213                  0.190077  \n",
       "1          0.135825                  0.184723  \n",
       "2          0.260090                  0.161074  \n",
       "0          0.213709                  0.178624  \n",
       "0         -0.112507                 -0.147592  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(correlations_240_passages('score', only_4_scores=True))\n",
    "display(correlations_1st_120_passages('score', only_4_scores=True))\n",
    "display(correlations_2nd_120_passages('score', only_4_scores=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7902d",
   "metadata": {},
   "source": [
    "## Correlations for the 3-score evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b845a9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 4-score</th>\n",
       "      <th>GPT4 4-score cot 2.6</th>\n",
       "      <th>GPT4 3-score 2.7</th>\n",
       "      <th>GPT4 3-score 2.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.462148</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.364067</td>\n",
       "      <td>0.365758</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.327731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.462148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425263</td>\n",
       "      <td>0.353236</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>0.297525</td>\n",
       "      <td>0.325495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.435904</td>\n",
       "      <td>0.425263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433279</td>\n",
       "      <td>0.329164</td>\n",
       "      <td>0.405653</td>\n",
       "      <td>0.373688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.449026</td>\n",
       "      <td>0.443706</td>\n",
       "      <td>0.430584</td>\n",
       "      <td>0.383527</td>\n",
       "      <td>0.307601</td>\n",
       "      <td>0.335626</td>\n",
       "      <td>0.342305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>-0.010521</td>\n",
       "      <td>-0.057578</td>\n",
       "      <td>-0.133504</td>\n",
       "      <td>-0.105479</td>\n",
       "      <td>-0.098800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson       a1       a2        a3  \\\n",
       "0                                     a1      NaN 0.462148  0.435904   \n",
       "1                                     a2 0.462148      NaN  0.425263   \n",
       "2                                     a3 0.435904 0.425263       NaN   \n",
       "0                                   mean 0.449026 0.443706  0.430584   \n",
       "0  Difference from mean human annotators 0.007921 0.002600 -0.010521   \n",
       "\n",
       "   GPT4 4-score  GPT4 4-score cot 2.6  GPT4 3-score 2.7  GPT4 3-score 2.9  \n",
       "0      0.364067              0.365758          0.303700          0.327731  \n",
       "1      0.353236              0.227882          0.297525          0.325495  \n",
       "2      0.433279              0.329164          0.405653          0.373688  \n",
       "0      0.383527              0.307601          0.335626          0.342305  \n",
       "0     -0.057578             -0.133504         -0.105479         -0.098800  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 1st 4-score</th>\n",
       "      <th>GPT4 1st 3-score 2.7</th>\n",
       "      <th>GPT4 1st 3-score 2.9</th>\n",
       "      <th>GPT4 1st 4-score cot 2.6</th>\n",
       "      <th>GPT4 1st 4-score cot 3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.486323</td>\n",
       "      <td>0.566787</td>\n",
       "      <td>0.423816</td>\n",
       "      <td>0.388535</td>\n",
       "      <td>0.402289</td>\n",
       "      <td>0.448939</td>\n",
       "      <td>0.435696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.486323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.470389</td>\n",
       "      <td>0.469790</td>\n",
       "      <td>0.434716</td>\n",
       "      <td>0.447627</td>\n",
       "      <td>0.259559</td>\n",
       "      <td>0.294047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.566787</td>\n",
       "      <td>0.470389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504886</td>\n",
       "      <td>0.506974</td>\n",
       "      <td>0.442885</td>\n",
       "      <td>0.427728</td>\n",
       "      <td>0.407101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.526555</td>\n",
       "      <td>0.478356</td>\n",
       "      <td>0.518588</td>\n",
       "      <td>0.466164</td>\n",
       "      <td>0.443408</td>\n",
       "      <td>0.430934</td>\n",
       "      <td>0.378742</td>\n",
       "      <td>0.378948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>-0.029477</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>-0.041669</td>\n",
       "      <td>-0.064425</td>\n",
       "      <td>-0.076899</td>\n",
       "      <td>-0.129091</td>\n",
       "      <td>-0.128885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson       a1        a2       a3  \\\n",
       "0                                     a1      NaN  0.486323 0.566787   \n",
       "1                                     a2 0.486323       NaN 0.470389   \n",
       "2                                     a3 0.566787  0.470389      NaN   \n",
       "0                                   mean 0.526555  0.478356 0.518588   \n",
       "0  Difference from mean human annotators 0.018722 -0.029477 0.010755   \n",
       "\n",
       "   GPT4 1st 4-score  GPT4 1st 3-score 2.7  GPT4 1st 3-score 2.9  \\\n",
       "0          0.423816              0.388535              0.402289   \n",
       "1          0.469790              0.434716              0.447627   \n",
       "2          0.504886              0.506974              0.442885   \n",
       "0          0.466164              0.443408              0.430934   \n",
       "0         -0.041669             -0.064425             -0.076899   \n",
       "\n",
       "   GPT4 1st 4-score cot 2.6  GPT4 1st 4-score cot 3.0  \n",
       "0                  0.448939                  0.435696  \n",
       "1                  0.259559                  0.294047  \n",
       "2                  0.427728                  0.407101  \n",
       "0                  0.378742                  0.378948  \n",
       "0                 -0.129091                 -0.128885  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 2nd 4-score</th>\n",
       "      <th>GPT4 2nd 3-score 2.7</th>\n",
       "      <th>GPT4 2nd 3-score 2.8</th>\n",
       "      <th>GPT4 2nd 3-score 2.9</th>\n",
       "      <th>GPT4 2nd 4-score cot 2.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408512</td>\n",
       "      <td>0.301099</td>\n",
       "      <td>0.309821</td>\n",
       "      <td>0.230688</td>\n",
       "      <td>0.135827</td>\n",
       "      <td>0.259653</td>\n",
       "      <td>0.292677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.408512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378775</td>\n",
       "      <td>0.240262</td>\n",
       "      <td>0.175341</td>\n",
       "      <td>0.124684</td>\n",
       "      <td>0.210932</td>\n",
       "      <td>0.214206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.301099</td>\n",
       "      <td>0.378775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362584</td>\n",
       "      <td>0.305838</td>\n",
       "      <td>0.245915</td>\n",
       "      <td>0.305392</td>\n",
       "      <td>0.233434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.354805</td>\n",
       "      <td>0.393643</td>\n",
       "      <td>0.339937</td>\n",
       "      <td>0.304222</td>\n",
       "      <td>0.237289</td>\n",
       "      <td>0.168809</td>\n",
       "      <td>0.258659</td>\n",
       "      <td>0.246773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>-0.007990</td>\n",
       "      <td>0.030848</td>\n",
       "      <td>-0.022858</td>\n",
       "      <td>-0.058573</td>\n",
       "      <td>-0.125506</td>\n",
       "      <td>-0.193986</td>\n",
       "      <td>-0.104136</td>\n",
       "      <td>-0.116022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson        a1       a2        a3  \\\n",
       "0                                     a1       NaN 0.408512  0.301099   \n",
       "1                                     a2  0.408512      NaN  0.378775   \n",
       "2                                     a3  0.301099 0.378775       NaN   \n",
       "0                                   mean  0.354805 0.393643  0.339937   \n",
       "0  Difference from mean human annotators -0.007990 0.030848 -0.022858   \n",
       "\n",
       "   GPT4 2nd 4-score  GPT4 2nd 3-score 2.7  GPT4 2nd 3-score 2.8  \\\n",
       "0          0.309821              0.230688              0.135827   \n",
       "1          0.240262              0.175341              0.124684   \n",
       "2          0.362584              0.305838              0.245915   \n",
       "0          0.304222              0.237289              0.168809   \n",
       "0         -0.058573             -0.125506             -0.193986   \n",
       "\n",
       "   GPT4 2nd 3-score 2.9  GPT4 2nd 4-score cot 2.6  \n",
       "0              0.259653                  0.292677  \n",
       "1              0.210932                  0.214206  \n",
       "2              0.305392                  0.233434  \n",
       "0              0.258659                  0.246773  \n",
       "0             -0.104136                 -0.116022  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(correlations_240_passages('03_score'))\n",
    "display(correlations_1st_120_passages('03_score'))\n",
    "display(correlations_2nd_120_passages('03_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7d440",
   "metadata": {},
   "source": [
    "## Correlations for the 2-score evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89b05a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 4-score</th>\n",
       "      <th>GPT4 4-score cot 2.6</th>\n",
       "      <th>GPT4 3-score 2.7</th>\n",
       "      <th>GPT4 3-score 2.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.408333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551797</td>\n",
       "      <td>0.484144</td>\n",
       "      <td>0.389271</td>\n",
       "      <td>0.420948</td>\n",
       "      <td>0.447044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.551797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525926</td>\n",
       "      <td>0.496907</td>\n",
       "      <td>0.496802</td>\n",
       "      <td>0.488818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.542565</td>\n",
       "      <td>0.555065</td>\n",
       "      <td>0.483912</td>\n",
       "      <td>0.462059</td>\n",
       "      <td>0.439250</td>\n",
       "      <td>0.448065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>-0.005256</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>-0.063909</td>\n",
       "      <td>-0.085762</td>\n",
       "      <td>-0.108571</td>\n",
       "      <td>-0.099756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson        a1        a2       a3  \\\n",
       "0                                     a1       NaN  0.533333 0.558333   \n",
       "1                                     a2  0.533333       NaN 0.551797   \n",
       "2                                     a3  0.558333  0.551797      NaN   \n",
       "0                                   mean  0.545833  0.542565 0.555065   \n",
       "0  Difference from mean human annotators -0.001988 -0.005256 0.007244   \n",
       "\n",
       "   GPT4 4-score  GPT4 4-score cot 2.6  GPT4 3-score 2.7  GPT4 3-score 2.9  \n",
       "0      0.441667              0.500000          0.400000          0.408333  \n",
       "1      0.484144              0.389271          0.420948          0.447044  \n",
       "2      0.525926              0.496907          0.496802          0.488818  \n",
       "0      0.483912              0.462059          0.439250          0.448065  \n",
       "0     -0.063909             -0.085762         -0.108571         -0.099756  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 1st 4-score</th>\n",
       "      <th>GPT4 1st 3-score 2.7</th>\n",
       "      <th>GPT4 1st 3-score 2.9</th>\n",
       "      <th>GPT4 1st 4-score cot 2.6</th>\n",
       "      <th>GPT4 1st 4-score cot 3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.677054</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.405099</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.469169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.393782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.677054</td>\n",
       "      <td>0.566474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546473</td>\n",
       "      <td>0.526894</td>\n",
       "      <td>0.509029</td>\n",
       "      <td>0.495114</td>\n",
       "      <td>0.479816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.591468</td>\n",
       "      <td>0.536178</td>\n",
       "      <td>0.621764</td>\n",
       "      <td>0.532813</td>\n",
       "      <td>0.499489</td>\n",
       "      <td>0.492263</td>\n",
       "      <td>0.451328</td>\n",
       "      <td>0.447589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>-0.046959</td>\n",
       "      <td>0.038627</td>\n",
       "      <td>-0.050324</td>\n",
       "      <td>-0.083648</td>\n",
       "      <td>-0.090874</td>\n",
       "      <td>-0.131808</td>\n",
       "      <td>-0.135548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson       a1        a2       a3  \\\n",
       "0                                     a1      NaN  0.505882 0.677054   \n",
       "1                                     a2 0.505882       NaN 0.566474   \n",
       "2                                     a3 0.677054  0.566474      NaN   \n",
       "0                                   mean 0.591468  0.536178 0.621764   \n",
       "0  Difference from mean human annotators 0.008331 -0.046959 0.038627   \n",
       "\n",
       "   GPT4 1st 4-score  GPT4 1st 3-score 2.7  GPT4 1st 3-score 2.9  \\\n",
       "0          0.426966              0.405099              0.386364   \n",
       "1          0.625000              0.566474              0.581395   \n",
       "2          0.546473              0.526894              0.509029   \n",
       "0          0.532813              0.499489              0.492263   \n",
       "0         -0.050324             -0.083648             -0.090874   \n",
       "\n",
       "   GPT4 1st 4-score cot 2.6  GPT4 1st 4-score cot 3.0  \n",
       "0                  0.483871                  0.469169  \n",
       "1                  0.375000                  0.393782  \n",
       "2                  0.495114                  0.479816  \n",
       "0                  0.451328                  0.447589  \n",
       "0                 -0.131808                 -0.135548  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 2nd 4-score</th>\n",
       "      <th>GPT4 2nd 3-score 2.7</th>\n",
       "      <th>GPT4 2nd 3-score 2.8</th>\n",
       "      <th>GPT4 2nd 3-score 2.9</th>\n",
       "      <th>GPT4 2nd 4-score cot 2.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.466307</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.284974</td>\n",
       "      <td>0.436997</td>\n",
       "      <td>0.535912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.300813</td>\n",
       "      <td>0.201278</td>\n",
       "      <td>0.331158</td>\n",
       "      <td>0.435216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504556</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.363208</td>\n",
       "      <td>0.467963</td>\n",
       "      <td>0.497768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.485538</td>\n",
       "      <td>0.532449</td>\n",
       "      <td>0.492563</td>\n",
       "      <td>0.444188</td>\n",
       "      <td>0.391443</td>\n",
       "      <td>0.283153</td>\n",
       "      <td>0.412040</td>\n",
       "      <td>0.489632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>-0.017979</td>\n",
       "      <td>0.028932</td>\n",
       "      <td>-0.010954</td>\n",
       "      <td>-0.059328</td>\n",
       "      <td>-0.112073</td>\n",
       "      <td>-0.220363</td>\n",
       "      <td>-0.091477</td>\n",
       "      <td>-0.013885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson        a1       a2        a3  \\\n",
       "0                                     a1       NaN 0.525424  0.445652   \n",
       "1                                     a2  0.525424      NaN  0.539474   \n",
       "2                                     a3  0.445652 0.539474       NaN   \n",
       "0                                   mean  0.485538 0.532449  0.492563   \n",
       "0  Difference from mean human annotators -0.017979 0.028932 -0.010954   \n",
       "\n",
       "   GPT4 2nd 4-score  GPT4 2nd 3-score 2.7  GPT4 2nd 3-score 2.8  \\\n",
       "0          0.466307              0.408000              0.284974   \n",
       "1          0.361702              0.300813              0.201278   \n",
       "2          0.504556              0.465517              0.363208   \n",
       "0          0.444188              0.391443              0.283153   \n",
       "0         -0.059328             -0.112073             -0.220363   \n",
       "\n",
       "   GPT4 2nd 3-score 2.9  GPT4 2nd 4-score cot 2.6  \n",
       "0              0.436997                  0.535912  \n",
       "1              0.331158                  0.435216  \n",
       "2              0.467963                  0.497768  \n",
       "0              0.412040                  0.489632  \n",
       "0             -0.091477                 -0.013885  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(correlations_240_passages('02_score'))\n",
    "display(correlations_1st_120_passages('02_score'))\n",
    "display(correlations_2nd_120_passages('02_score'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd390a8",
   "metadata": {},
   "source": [
    "## Correlations for the alternate 2-score evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7484ecbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 4-score</th>\n",
       "      <th>GPT4 4-score cot 2.6</th>\n",
       "      <th>GPT4 3-score 2.7</th>\n",
       "      <th>GPT4 3-score 2.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.660554</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.410637</td>\n",
       "      <td>0.417773</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>0.343201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.660554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720741</td>\n",
       "      <td>0.464943</td>\n",
       "      <td>0.460943</td>\n",
       "      <td>0.421045</td>\n",
       "      <td>0.414590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.719626</td>\n",
       "      <td>0.720741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487970</td>\n",
       "      <td>0.470603</td>\n",
       "      <td>0.396565</td>\n",
       "      <td>0.390441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.690090</td>\n",
       "      <td>0.690647</td>\n",
       "      <td>0.720183</td>\n",
       "      <td>0.454517</td>\n",
       "      <td>0.449773</td>\n",
       "      <td>0.382683</td>\n",
       "      <td>0.382744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>-0.010217</td>\n",
       "      <td>-0.009660</td>\n",
       "      <td>0.019876</td>\n",
       "      <td>-0.245790</td>\n",
       "      <td>-0.250534</td>\n",
       "      <td>-0.317624</td>\n",
       "      <td>-0.317563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson        a1        a2       a3  \\\n",
       "0                                     a1       NaN  0.660554 0.719626   \n",
       "1                                     a2  0.660554       NaN 0.720741   \n",
       "2                                     a3  0.719626  0.720741      NaN   \n",
       "0                                   mean  0.690090  0.690647 0.720183   \n",
       "0  Difference from mean human annotators -0.010217 -0.009660 0.019876   \n",
       "\n",
       "   GPT4 4-score  GPT4 4-score cot 2.6  GPT4 3-score 2.7  GPT4 3-score 2.9  \n",
       "0      0.410637              0.417773          0.330440          0.343201  \n",
       "1      0.464943              0.460943          0.421045          0.414590  \n",
       "2      0.487970              0.470603          0.396565          0.390441  \n",
       "0      0.454517              0.449773          0.382683          0.382744  \n",
       "0     -0.245790             -0.250534         -0.317624         -0.317563  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 1st 4-score</th>\n",
       "      <th>GPT4 1st 3-score 2.7</th>\n",
       "      <th>GPT4 1st 3-score 2.9</th>\n",
       "      <th>GPT4 1st 4-score cot 2.6</th>\n",
       "      <th>GPT4 1st 4-score cot 3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.336918</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.404762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.372760</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.484127</td>\n",
       "      <td>0.404762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.375372</td>\n",
       "      <td>0.350962</td>\n",
       "      <td>0.528796</td>\n",
       "      <td>0.410995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.794034</td>\n",
       "      <td>0.794034</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.572244</td>\n",
       "      <td>0.361683</td>\n",
       "      <td>0.348871</td>\n",
       "      <td>0.485789</td>\n",
       "      <td>0.406840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>-0.018150</td>\n",
       "      <td>-0.018150</td>\n",
       "      <td>0.036301</td>\n",
       "      <td>-0.239940</td>\n",
       "      <td>-0.450501</td>\n",
       "      <td>-0.463313</td>\n",
       "      <td>-0.326395</td>\n",
       "      <td>-0.405345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson        a1        a2       a3  \\\n",
       "0                                     a1       NaN  0.739583 0.848485   \n",
       "1                                     a2  0.739583       NaN 0.848485   \n",
       "2                                     a3  0.848485  0.848485      NaN   \n",
       "0                                   mean  0.794034  0.794034 0.848485   \n",
       "0  Difference from mean human annotators -0.018150 -0.018150 0.036301   \n",
       "\n",
       "   GPT4 1st 4-score  GPT4 1st 3-score 2.7  GPT4 1st 3-score 2.9  \\\n",
       "0          0.545455              0.336918              0.347826   \n",
       "1          0.606061              0.372760              0.347826   \n",
       "2          0.565217              0.375372              0.350962   \n",
       "0          0.572244              0.361683              0.348871   \n",
       "0         -0.239940             -0.450501             -0.463313   \n",
       "\n",
       "   GPT4 1st 4-score cot 2.6  GPT4 1st 4-score cot 3.0  \n",
       "0                  0.444444                  0.404762  \n",
       "1                  0.484127                  0.404762  \n",
       "2                  0.528796                  0.410995  \n",
       "0                  0.485789                  0.406840  \n",
       "0                 -0.326395                 -0.405345  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparisson</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>GPT4 2nd 4-score</th>\n",
       "      <th>GPT4 2nd 3-score 2.7</th>\n",
       "      <th>GPT4 2nd 3-score 2.8</th>\n",
       "      <th>GPT4 2nd 3-score 2.9</th>\n",
       "      <th>GPT4 2nd 4-score cot 2.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.599057</td>\n",
       "      <td>0.288321</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.393064</td>\n",
       "      <td>0.340452</td>\n",
       "      <td>0.392458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610811</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.479070</td>\n",
       "      <td>0.450847</td>\n",
       "      <td>0.487023</td>\n",
       "      <td>0.444628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>0.599057</td>\n",
       "      <td>0.610811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413408</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.409190</td>\n",
       "      <td>0.432356</td>\n",
       "      <td>0.408659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.595957</td>\n",
       "      <td>0.601834</td>\n",
       "      <td>0.604934</td>\n",
       "      <td>0.351243</td>\n",
       "      <td>0.408761</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.419944</td>\n",
       "      <td>0.415248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference from mean human annotators</td>\n",
       "      <td>-0.004951</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>-0.249665</td>\n",
       "      <td>-0.192147</td>\n",
       "      <td>-0.183208</td>\n",
       "      <td>-0.180965</td>\n",
       "      <td>-0.185660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             comparisson        a1       a2       a3  \\\n",
       "0                                     a1       NaN 0.592857 0.599057   \n",
       "1                                     a2  0.592857      NaN 0.610811   \n",
       "2                                     a3  0.599057 0.610811      NaN   \n",
       "0                                   mean  0.595957 0.601834 0.604934   \n",
       "0  Difference from mean human annotators -0.004951 0.000926 0.004026   \n",
       "\n",
       "   GPT4 2nd 4-score  GPT4 2nd 3-score 2.7  GPT4 2nd 3-score 2.8  \\\n",
       "0          0.288321              0.326923              0.393064   \n",
       "1          0.352000              0.479070              0.450847   \n",
       "2          0.413408              0.420290              0.409190   \n",
       "0          0.351243              0.408761              0.417700   \n",
       "0         -0.249665             -0.192147             -0.183208   \n",
       "\n",
       "   GPT4 2nd 3-score 2.9  GPT4 2nd 4-score cot 2.6  \n",
       "0              0.340452                  0.392458  \n",
       "1              0.487023                  0.444628  \n",
       "2              0.432356                  0.408659  \n",
       "0              0.419944                  0.415248  \n",
       "0             -0.180965                 -0.185660  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(correlations_240_passages('02_score_alt'))\n",
    "display(correlations_1st_120_passages('02_score_alt'))\n",
    "display(correlations_2nd_120_passages('02_score_alt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85661198",
   "metadata": {},
   "source": [
    "# Check the agreement per question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8d01b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_per_question(which_score):\n",
    "\n",
    "    all_results = []\n",
    "    \n",
    "    res_a1_a2 = check_agreement_per_questions(a1_df, a2_df, suffix=\"_a1_a2\", score=which_score)\n",
    "    res_a1_a3 = check_agreement_per_questions(a1_df, a3_df, suffix=\"_a1_a3\", score=which_score)\n",
    "    res_a2_a3 = check_agreement_per_questions(a2_df, a3_df, suffix=\"_a2_a3\", score=which_score)\n",
    "\n",
    "    res_a1_gpt4 = check_agreement_per_questions(a1_df, gpt4_df, \"_a1_gpt4\", score=which_score)\n",
    "    res_a2_gpt4 = check_agreement_per_questions(a2_df, gpt4_df, \"_a2_gpt4\", score=which_score)\n",
    "    res_a3_gpt4 = check_agreement_per_questions(a3_df, gpt4_df, \"_a3_gpt4\", score=which_score)\n",
    "\n",
    "    res_a1_gpt4_cot_2_6 = check_agreement_per_questions(a1_df, gpt4_cot_2_6_df, \"_a1_gpt4_cot_2.6\", score=which_score)\n",
    "    res_a2_gpt4_cot_2_6 = check_agreement_per_questions(a2_df, gpt4_cot_2_6_df, \"_a2_gpt4_cot_2.6\", score=which_score)\n",
    "    res_a3_gpt4_cot_2_6 = check_agreement_per_questions(a3_df, gpt4_cot_2_6_df, \"_a3_gpt4_cot_2.6\", score=which_score)\n",
    "\n",
    "    if which_score != 'score':\n",
    "        res_a1_gpt4_2_7 = check_agreement_per_questions(a1_df, gpt4_03_score_2_7_df, \"_a1_gpt4_2.7\", score=which_score)\n",
    "        res_a2_gpt4_2_7 = check_agreement_per_questions(a2_df, gpt4_03_score_2_7_df, \"_a2_gpt4_2.7\", score=which_score)\n",
    "        res_a3_gpt4_2_7 = check_agreement_per_questions(a3_df, gpt4_03_score_2_7_df, \"_a3_gpt4_2.7\", score=which_score)\n",
    "\n",
    "        res_a1_gpt4_2_9 = check_agreement_per_questions(a1_df, gpt4_03_score_2_9_df, \"_a1_gpt4_2.9\", score=which_score)\n",
    "        res_a2_gpt4_2_9 = check_agreement_per_questions(a2_df, gpt4_03_score_2_9_df, \"_a2_gpt4_2.9\", score=which_score)\n",
    "        res_a3_gpt4_2_9 = check_agreement_per_questions(a3_df, gpt4_03_score_2_9_df, \"_a3_gpt4_2.9\", score=which_score)\n",
    "    \n",
    "    \n",
    "    human_combined_res = pd.concat([res_a1_a2[1], res_a1_a3[1].iloc[:, -1], res_a2_a3[1].iloc[:, -1]], axis=1)\n",
    "\n",
    "    human_combined_res['cohen_kappa_mean'] = human_combined_res.iloc[:, 1:].mean(axis=1)\n",
    "    human_combined_res['cohen_kappa_std'] = human_combined_res.iloc[:, 1:].std(axis=1)\n",
    "    \n",
    "    all_results.append(human_combined_res)\n",
    "    \n",
    "    human_gpt4_combined_res = pd.concat([res_a1_gpt4[1], res_a2_gpt4[1].iloc[:, -1], res_a3_gpt4[1].iloc[:, -1]], axis=1)\n",
    "    human_gpt4_combined_res['cohen_kappa_mean'] = human_gpt4_combined_res.iloc[:, 1:].mean(axis=1)\n",
    "    human_gpt4_combined_res['cohen_kappa_std'] = human_gpt4_combined_res.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "    all_results.append(human_gpt4_combined_res)    \n",
    "    \n",
    "    human_gpt4_cot_2_6_combined_res = pd.concat([res_a1_gpt4_cot_2_6[1], res_a2_gpt4_cot_2_6[1].iloc[:, -1], res_a3_gpt4_cot_2_6[1].iloc[:, -1]], axis=1)\n",
    "    human_gpt4_cot_2_6_combined_res['cohen_kappa_mean'] = human_gpt4_cot_2_6_combined_res.iloc[:, 1:].mean(axis=1)\n",
    "    human_gpt4_cot_2_6_combined_res['cohen_kappa_std'] = human_gpt4_cot_2_6_combined_res.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "    all_results.append(human_gpt4_cot_2_6_combined_res)    \n",
    "\n",
    "    if which_score != 'score':\n",
    "        human_gpt4_2_7_combined_res = pd.concat([res_a1_gpt4_2_7[1], res_a2_gpt4_2_7[1].iloc[:, -1], res_a3_gpt4_2_7[1].iloc[:, -1]], axis=1)\n",
    "        human_gpt4_2_7_combined_res['cohen_kappa_mean'] = human_gpt4_2_7_combined_res.iloc[:, 1:].mean(axis=1)\n",
    "        human_gpt4_2_7_combined_res['cohen_kappa_std'] = human_gpt4_2_7_combined_res.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "        all_results.append(human_gpt4_2_7_combined_res)    \n",
    "        \n",
    "        human_gpt4_2_9_combined_res = pd.concat([res_a1_gpt4_2_9[1], res_a2_gpt4_2_9[1].iloc[:, -1], res_a3_gpt4_2_9[1].iloc[:, -1]], axis=1)\n",
    "        human_gpt4_2_9_combined_res['cohen_kappa_mean'] = human_gpt4_2_9_combined_res.iloc[:, 1:].mean(axis=1)\n",
    "        human_gpt4_2_9_combined_res['cohen_kappa_std'] = human_gpt4_2_9_combined_res.iloc[:, 1:].std(axis=1)\n",
    "    \n",
    "        all_results.append(human_gpt4_2_9_combined_res)    \n",
    "    \n",
    "    \n",
    "    correlations = []\n",
    "    correlations.append({'annotator': 'human',\n",
    "                         'cohen_kappa': human_combined_res['cohen_kappa_mean'].mean()})\n",
    "    \n",
    "    correlations.append({'annotator': 'GPT-4',\n",
    "                         'cohen_kappa': human_gpt4_combined_res['cohen_kappa_mean'].mean()})\n",
    "    correlations.append({'annotator': 'GPT-4 CoT 2.6',\n",
    "                         'cohen_kappa': human_gpt4_cot_2_6_combined_res['cohen_kappa_mean'].mean()})\n",
    "\n",
    "    if which_score != 'score':\n",
    "        correlations.append({'annotator': 'GPT-4 2.7',\n",
    "                             'cohen_kappa': human_gpt4_2_7_combined_res['cohen_kappa_mean'].mean()})\n",
    "        correlations.append({'annotator': 'GPT-4 2.9',\n",
    "                             'cohen_kappa': human_gpt4_2_9_combined_res['cohen_kappa_mean'].mean()})\n",
    "        \n",
    "    \n",
    "    \n",
    "    correlations_df = pd.DataFrame(correlations)\n",
    "    \n",
    "    correlations_df['difference'] = correlations_df['cohen_kappa'] - human_combined_res['cohen_kappa_mean'].mean()\n",
    "    \n",
    "    display(correlations_df)\n",
    "    \n",
    "    return correlations_df, all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488ca4f7",
   "metadata": {},
   "source": [
    "### Check for 4-score evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e861e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>cohen_kappa</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0.322864</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.219317</td>\n",
       "      <td>-0.103547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4 CoT 2.6</td>\n",
       "      <td>0.161981</td>\n",
       "      <td>-0.160883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotator  cohen_kappa  difference\n",
       "0          human     0.322864    0.000000\n",
       "1          GPT-4     0.219317   -0.103547\n",
       "2  GPT-4 CoT 2.6     0.161981   -0.160883"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = correlation_per_question('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb37402",
   "metadata": {},
   "source": [
    "### Check for 3-score evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f89c5778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>cohen_kappa</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0.307239</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.235552</td>\n",
       "      <td>-0.071687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4 CoT 2.6</td>\n",
       "      <td>0.187160</td>\n",
       "      <td>-0.120079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4 2.7</td>\n",
       "      <td>0.206327</td>\n",
       "      <td>-0.100913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-4 2.9</td>\n",
       "      <td>0.209162</td>\n",
       "      <td>-0.098078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotator  cohen_kappa  difference\n",
       "0          human     0.307239    0.000000\n",
       "1          GPT-4     0.235552   -0.071687\n",
       "2  GPT-4 CoT 2.6     0.187160   -0.120079\n",
       "3      GPT-4 2.7     0.206327   -0.100913\n",
       "4      GPT-4 2.9     0.209162   -0.098078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_3_df = correlation_per_question('03_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11baac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>cohen_kappa</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0.452085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.332523</td>\n",
       "      <td>-0.119562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4 CoT 2.6</td>\n",
       "      <td>0.310131</td>\n",
       "      <td>-0.141954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4 2.7</td>\n",
       "      <td>0.330763</td>\n",
       "      <td>-0.121322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-4 2.9</td>\n",
       "      <td>0.332203</td>\n",
       "      <td>-0.119882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotator  cohen_kappa  difference\n",
       "0          human     0.452085    0.000000\n",
       "1          GPT-4     0.332523   -0.119562\n",
       "2  GPT-4 CoT 2.6     0.310131   -0.141954\n",
       "3      GPT-4 2.7     0.330763   -0.121322\n",
       "4      GPT-4 2.9     0.332203   -0.119882"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_2_df = correlation_per_question('02_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b18498a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
      "/home/eduseiti/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:697: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator</th>\n",
       "      <th>cohen_kappa</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>0.706175</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.506944</td>\n",
       "      <td>-0.199231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT-4 CoT 2.6</td>\n",
       "      <td>0.444078</td>\n",
       "      <td>-0.262097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT-4 2.7</td>\n",
       "      <td>0.374782</td>\n",
       "      <td>-0.331392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-4 2.9</td>\n",
       "      <td>0.361484</td>\n",
       "      <td>-0.344691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotator  cohen_kappa  difference\n",
       "0          human     0.706175    0.000000\n",
       "1          GPT-4     0.506944   -0.199231\n",
       "2  GPT-4 CoT 2.6     0.444078   -0.262097\n",
       "3      GPT-4 2.7     0.374782   -0.331392\n",
       "4      GPT-4 2.9     0.361484   -0.344691"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_2a_df = correlation_per_question('02_score_alt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6e19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
